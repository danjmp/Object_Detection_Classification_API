{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection and Classification Using TensorFlow (CPU) on Windows 10.\n",
    "\n",
    "### Spring position detection and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explain how I have trained an Object Detection and Classification API using my own data. In my case I will be detecting and classifying springs position of a valve used in the assembly of gas cook-tops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter nootebook is based completely in a tutorial called \"How To Train an Object Detection Classifier for Multiple Objects Using TensorFlow (GPU) on Windows 10\" done by Evan Juras. His tutorial is great and well detailed. This notebook is a simplified version of his guide applied to a real problem placed in a manufaturing line. For more details about his didactic document follow the link below:\n",
    "\n",
    "https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10\n",
    "\n",
    "\n",
    "\n",
    "In a future I am planning to translate his tutorial to Spanish and Portuguese as I think his work is great and must be shared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images_API/BOTH_29.png\" alt=\"Drawing\" style=\"width: 250px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading the necessary files to build use the object detection API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you must go to the tutorial of Evan Juras at https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10 and follow his steps in how to download and organize all the files necessary to build the object detection API.\n",
    "\n",
    "P.S. From this point I haven't followed exactly his steps because I have changed some details of his tutorial. These details are referent to the python virtual env and folder names and I also changed his file \"Object_detection_image.py\" to adapt to my problem and to the outputs I want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Python Virtual Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the anaconda prompt I typed the follow command. It creates an virtual environment called \"ComputerVision\" in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```console\n",
    "C:\\> conda create -n ComputerVision pip python=3.7 \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activating the Python Virtual Environment and update pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```console\n",
    "C:\\> activate ComputerVision\n",
    "\n",
    "(ComputerVision) C:\\>python -m pip install --upgrade pip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing tensorflow CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```console\n",
    "\n",
    "(ComputerVision) C:\\> pip install --ignore-installed --upgrade tensorflow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing the necessary packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had problems installing protobuf. The only version that worked for me was the 3.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```console\n",
    "\n",
    "(ComputerVision) C:\\> conda install -c anaconda protobuf=3.6\n",
    "(ComputerVision) C:\\> pip install pillow\n",
    "(ComputerVision) C:\\> pip install lxml\n",
    "(ComputerVision) C:\\> pip install Cython\n",
    "(ComputerVision) C:\\> pip install contextlib2\n",
    "(ComputerVision) C:\\> pip install jupyter\n",
    "(ComputerVision) C:\\> pip install matplotlib\n",
    "(ComputerVision) C:\\> pip install pandas\n",
    "(ComputerVision) C:\\> pip install opencv-python\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure PYTHONPATH environment variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```console\n",
    "(ComputerVision) C:\\> set PYTHONPATH=C:\\ComputerVision\\models;C:\\ComputerVision\\models\\research;C:\\ComputerVision\\models\\research\\slim\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile Protobufs and run setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the folder \n",
    "```console\n",
    "(ComputerVision) C:\\ComputerVision\\models\\research\n",
    "```\n",
    "I have done:\n",
    "```console\n",
    "protoc --python_out=. .\\object_detection\\protos\\anchor_generator.proto .\\object_detection\\protos\\argmax_matcher.proto .\\object_detection\\protos\\bipartite_matcher.proto .\\object_detection\\protos\\box_coder.proto .\\object_detection\\protos\\box_predictor.proto .\\object_detection\\protos\\eval.proto .\\object_detection\\protos\\faster_rcnn.proto .\\object_detection\\protos\\faster_rcnn_box_coder.proto .\\object_detection\\protos\\grid_anchor_generator.proto .\\object_detection\\protos\\hyperparams.proto .\\object_detection\\protos\\image_resizer.proto .\\object_detection\\protos\\input_reader.proto .\\object_detection\\protos\\losses.proto .\\object_detection\\protos\\matcher.proto .\\object_detection\\protos\\mean_stddev_box_coder.proto .\\object_detection\\protos\\model.proto .\\object_detection\\protos\\optimizer.proto .\\object_detection\\protos\\pipeline.proto .\\object_detection\\protos\\post_processing.proto .\\object_detection\\protos\\preprocessor.proto .\\object_detection\\protos\\region_similarity_calculator.proto .\\object_detection\\protos\\square_box_coder.proto .\\object_detection\\protos\\ssd.proto .\\object_detection\\protos\\ssd_anchor_generator.proto .\\object_detection\\protos\\string_int_label_map.proto .\\object_detection\\protos\\train.proto .\\object_detection\\protos\\keypoint_box_coder.proto .\\object_detection\\protos\\multiscale_anchor_generator.proto .\\object_detection\\protos\\graph_rewriter.proto .\\object_detection\\protos\\calibration.proto .\\object_detection\\protos\\flexible_grid_anchor_generator.proto\n",
    "```\n",
    "\n",
    "then:\n",
    "\n",
    "```console\n",
    "(ComputerVision) C:\\ComputerVision\\models\\research> python setup.py build\n",
    "(ComputerVision) C:\\ComputerVision\\models\\research> python setup.py install\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test TensorFlow setup to verify it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you must go to the tutorial of Evan Juras at https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10 and follow his steps to test if the API is working correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gather and Label Pictures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After taking pictures of valves with springs in the right position and with inclined springs it was time to label these pictures and for that I have used \"LabelImag\". More information about it you can find at https://github.com/tzutalin/labelImg#labelimg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After labelling the images I have one xml file for image corresponding to where the object I want to detect and classify was and its label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images_API/labelimg.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating the xml file for each image I put them into:\n",
    "```console\n",
    "C:\\ComputerVision\\models\\research\\object_detection\\images\n",
    "```\n",
    "In the corresponding folder, train or test. I have used 20% of my images for test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Generate Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After putting the images into the right folders I run:\n",
    "\n",
    "```console\n",
    "(ComputerVision) C:\\ComputerVision\\models\\research\\object_detection> python xml_to_csv.py\n",
    "```\n",
    "It generates 2 csv files into the folder \"images\", one corresponding for test and other for train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing some files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used notepad++ to make some changes in some files to adapt them to my problem. The first files to be changed is \"generate_tfrecord.py\" where I replaced the label map existing to my map (line 31). As I wanna identy if the spring is moved or not I am predicting two classes, OK and NOK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images_API/labelmap.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the TFRecord files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```console\n",
    "(ComputerVision) C:\\ComputerVision\\models\\research\\object_detection> python generate_tfrecord.py --csv_input=images\\train_labels.csv --image_dir=images\\train --output_path=train.record\n",
    "```\n",
    "\n",
    "```console\n",
    "(ComputerVision) C:\\ComputerVision\\models\\research\\object_detection> python generate_tfrecord.py --csv_input=images\\test_labels.csv --image_dir=images\\test --output_path=test.record\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Label Map and Configure Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using notepad++ I have created a file called labelmap.pbtxt and I put it into the folder\n",
    "```console\n",
    "C:\\ComputerVision\\models\\research\\object_detection\\training\n",
    "```\n",
    "\n",
    "This file contains my classes map. The sctructure of this file can be seen below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images_API/labelmappb.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have copied the file \"faster_rcnn_inception_v2_pets.config\" from the folder\n",
    "```console\n",
    "C:\\ComputerVision\\models\\research\\object_detection\\samples\\configs\n",
    "```\n",
    "\n",
    "And I past it into\n",
    "```console\n",
    "C:\\ComputerVision\\models\\research\\object_detection\\training\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I open the file \"faster_rcnn_inception_v2_pets.config\" that is into the training dir using notepad++ and have done few changes on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Line 9. I have changed num_classes to the number of different objects I have, in this case 2.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Line 106. I have changed the fine_tune_checkpoint:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```console\n",
    "fine_tune_checkpoint: \"C:/ComputerVision/models/research/object_detection/faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Lines 123 and 125. I have changed the input_path and the label_map_path:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```console\n",
    "input_path: \"C:/ComputerVision/models/research/object_detection/train.record\"\n",
    "```\n",
    "\n",
    "```console\n",
    "label_map_path: \"C:/ComputerVision/models/research/object_detection/training/labelmap.pbtxt\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Lines 130. I have changed the num_examples to the number of images I have in the \\images\\test directory, in this case, 185."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Lines 135 and 137. I have changed the input_path and the label_map_path:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```console\n",
    "input_path: \"C:/ComputerVision/models/research/object_detection/test.record\"\n",
    "```\n",
    "\n",
    "```console\n",
    "label_map_path: \"C:/ComputerVision/models/research/object_detection/training/labelmap.pbtxt\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the object_detection folder I have run:\n",
    "\n",
    "```console\n",
    "python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/faster_rcnn_inception_v2_pets.config\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to check how the model evaluation would be over time I have used tensorboard. To be able to do this I opened a new anaconda prompt without closing the other that was running the model and run:\n",
    "\n",
    "```console\n",
    "(ComputerVision) C:\\ComputerVision\\models\\research\\object_detection>tensorboard --logdir=training\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running more than 10k epochs I got a loss of around 0.1. And it is a great result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images_API/Loss_Inception.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the RCNN I have done some tests and it have showed great results, thus I started to use this model in the production line. In 5 days it was produced around 35k products and the model has detected 3 products presenting springs out of position and in all the cases it detected correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images_API/Detection_4.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
